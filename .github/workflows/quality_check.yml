name: ğŸ” Quality Assurance & Testing

on:
  # ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ™‚ã®å“è³ªãƒã‚§ãƒƒã‚¯
  pull_request:
    branches:
      - main
      - master
    paths:
      - 'src/**'
      - 'prompts/**'
      - 'package*.json'

  # æ‰‹å‹•å®Ÿè¡Œ
  workflow_dispatch:
    inputs:
      check_type:
        description: 'ãƒã‚§ãƒƒã‚¯ã‚¿ã‚¤ãƒ—ã‚’é¸æŠ'
        required: true
        type: choice
        options:
          - 'full'
          - 'code-only'
          - 'content-only'
        default: 'full'

  # å®šæœŸå®Ÿè¡Œï¼ˆæ¯é€±æœˆæ›œåˆå‰1æ™‚ï¼‰
  schedule:
    - cron: '0 1 * * 1'

env:
  NODE_VERSION: '18'

jobs:
  # ã‚³ãƒ¼ãƒ‰å“è³ªãƒã‚§ãƒƒã‚¯
  code-quality:
    name: ğŸ’» Code Quality Check
    runs-on: ubuntu-latest
    if: github.event.inputs.check_type != 'content-only'

    steps:
      - name: ğŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ğŸ—ï¸ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ğŸ“¦ Install Dependencies
        run: npm ci

      - name: ğŸ” ESLint Check
        run: |
          echo "ğŸ” Running ESLint..."
          if command -v npx >/dev/null 2>&1; then
            npx eslint src/ --ext .js,.json --format unix
            echo "âœ… ESLint check completed"
          else
            echo "âš ï¸ ESLint not configured, skipping"
          fi

      - name: ğŸ¨ Prettier Format Check
        run: |
          echo "ğŸ¨ Checking code formatting..."
          if command -v npx >/dev/null 2>&1; then
            npx prettier --check "src/**/*.js" "*.json" "*.md" || echo "âš ï¸ Some files are not properly formatted"
          else
            echo "âš ï¸ Prettier not configured, skipping"
          fi

      - name: ğŸ§ª Unit Tests
        run: |
          echo "ğŸ§ª Running unit tests..."
          if [ -d "tests/unit" ] && [ "$(ls -A tests/unit)" ]; then
            npm test
            echo "âœ… Unit tests completed"
          else
            echo "â„¹ï¸ No unit tests found, skipping"
          fi

      - name: ğŸ“Š Code Coverage Report
        run: |
          echo "ğŸ“Š Generating code coverage report..."
          if [ -f "coverage/lcov.info" ]; then
            echo "âœ… Coverage report generated"
          else
            echo "â„¹ï¸ No coverage data available"
          fi

  # ä¾å­˜é–¢ä¿‚ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯
  security-audit:
    name: ğŸ”’ Security Audit
    runs-on: ubuntu-latest
    if: github.event.inputs.check_type != 'content-only'

    steps:
      - name: ğŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ğŸ—ï¸ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ğŸ”’ NPM Security Audit
        run: |
          echo "ğŸ”’ Running security audit..."
          npm audit --audit-level=moderate
          echo "âœ… Security audit completed"

      - name: ğŸ“‹ Generate Security Report
        run: |
          echo "ğŸ“‹ Generating security summary..."
          npm audit --json > security-audit.json 2>/dev/null || true
          
          if [ -f security-audit.json ]; then
            echo "### ğŸ”’ Security Audit Summary" >> $GITHUB_STEP_SUMMARY
            echo "Security audit completed successfully" >> $GITHUB_STEP_SUMMARY
          fi

  # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å“è³ªãƒã‚§ãƒƒã‚¯
  content-quality:
    name: ğŸ“ Content Quality Check
    runs-on: ubuntu-latest
    if: github.event.inputs.check_type != 'code-only'

    steps:
      - name: ğŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ğŸ—ï¸ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ğŸ“¦ Install Dependencies
        run: npm ci

      - name: ğŸ“‹ Validate Prompt Files
        run: |
          echo "ğŸ“‹ Validating prompt files..."
          
          prompt_count=0
          error_count=0
          
          for file in *.md prompts/*.md 2>/dev/null; do
            if [ -f "$file" ]; then
              echo "Checking: $file"
              
              # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
              size=$(wc -c < "$file")
              if [ $size -gt 100000 ]; then
                echo "âš ï¸ Large file detected: $file ($size bytes)"
              fi
              
              # æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒã‚§ãƒƒã‚¯
              if file "$file" | grep -q "UTF-8"; then
                echo "âœ… UTF-8 encoding: $file"
              else
                echo "âš ï¸ Non-UTF-8 encoding: $file"
                ((error_count++))
              fi
              
              ((prompt_count++))
            fi
          done
          
          echo "### ğŸ“‹ Prompt File Validation" >> $GITHUB_STEP_SUMMARY
          echo "- **Total Files Checked**: $prompt_count" >> $GITHUB_STEP_SUMMARY
          echo "- **Encoding Errors**: $error_count" >> $GITHUB_STEP_SUMMARY

      - name: ğŸ” Test Sample Content Generation
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          echo "ğŸ” Testing content generation with sample data..."
          
          # ã‚µãƒ³ãƒ—ãƒ«ãƒªã‚µãƒ¼ãƒãƒ‡ãƒ¼ã‚¿ä½œæˆ
          mkdir -p inputs/research_results/pending
          cat > inputs/research_results/pending/sample_test.json << 'EOF'
          {
            "title": "freeeç¢ºå®šç”³å‘Šã®ä½¿ã„æ–¹ãƒ†ã‚¹ãƒˆ",
            "keywords": ["freee", "ç¢ºå®šç”³å‘Š", "ä½¿ã„æ–¹"],
            "targetAudience": "ä¼šè¨ˆã‚½ãƒ•ãƒˆåˆå¿ƒè€…",
            "contentType": "how-to",
            "sections": [
              {"title": "freeeç¢ºå®šç”³å‘Šã¨ã¯", "estimatedLength": "300"},
              {"title": "åˆæœŸè¨­å®šã®æ‰‹é †", "estimatedLength": "500"}
            ]
          }
          EOF
          
          # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
          if [ -n "$OPENAI_API_KEY" ]; then
            echo "ğŸ§ª Running content generation test..."
            mkdir -p logs outputs/{parsed_research,generated_content}
            
            if timeout 300 npm run parse-research; then
              echo "âœ… Research parsing test successful"
            else
              echo "âš ï¸ Research parsing test failed or timed out"
            fi
          else
            echo "âš ï¸ OPENAI_API_KEY not set, skipping content generation test"
          fi

      - name: ğŸ“Š WordPress Connection Test
        env:
          WORDPRESS_API_URL: ${{ secrets.WORDPRESS_API_URL }}
          WORDPRESS_USERNAME: ${{ secrets.WORDPRESS_USERNAME }}
          WORDPRESS_APP_PASSWORD: ${{ secrets.WORDPRESS_APP_PASSWORD }}
        run: |
          echo "ğŸ“Š Testing WordPress connection..."
          
          if [ -n "$WORDPRESS_API_URL" ] && [ -n "$WORDPRESS_USERNAME" ] && [ -n "$WORDPRESS_APP_PASSWORD" ]; then
            # WordPress APIæ¥ç¶šãƒ†ã‚¹ãƒˆ
            node -e "
              const WordPressClient = require('./src/core/wordpress_client');
              const client = new WordPressClient();
              client.testConnection()
                .then(success => {
                  console.log(success ? 'âœ… WordPressæ¥ç¶šãƒ†ã‚¹ãƒˆæˆåŠŸ' : 'âŒ WordPressæ¥ç¶šãƒ†ã‚¹ãƒˆå¤±æ•—');
                  process.exit(success ? 0 : 1);
                })
                .catch(error => {
                  console.error('âŒ WordPressæ¥ç¶šã‚¨ãƒ©ãƒ¼:', error.message);
                  process.exit(1);
                });
            "
          else
            echo "âš ï¸ WordPress credentials not set, skipping connection test"
          fi

  # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
  performance-test:
    name: âš¡ Performance Test
    runs-on: ubuntu-latest
    if: github.event.inputs.check_type == 'full'

    steps:
      - name: ğŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ğŸ—ï¸ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ğŸ“¦ Install Dependencies
        run: npm ci

      - name: âš¡ Memory Usage Test
        run: |
          echo "âš¡ Testing memory usage..."
          
          # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒ†ã‚¹ãƒˆ
          node -e "
            const usage = process.memoryUsage();
            console.log('Memory Usage:');
            console.log('- RSS:', Math.round(usage.rss / 1024 / 1024), 'MB');
            console.log('- Heap Used:', Math.round(usage.heapUsed / 1024 / 1024), 'MB');
            console.log('- Heap Total:', Math.round(usage.heapTotal / 1024 / 1024), 'MB');
            console.log('- External:', Math.round(usage.external / 1024 / 1024), 'MB');
            
            if (usage.heapUsed > 512 * 1024 * 1024) {
              console.log('âš ï¸ High memory usage detected');
              process.exit(1);
            } else {
              console.log('âœ… Memory usage within normal range');
            }
          "

      - name: â±ï¸ Processing Time Test
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          echo "â±ï¸ Testing processing time..."
          
          if [ -n "$OPENAI_API_KEY" ]; then
            start_time=$(date +%s)
            
            # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§å‡¦ç†æ™‚é–“ãƒ†ã‚¹ãƒˆ
            mkdir -p inputs/research_results/pending logs outputs/{parsed_research,generated_content}
            
            echo '{"title":"Performance Test","keywords":["test"],"contentType":"how-to"}' > inputs/research_results/pending/perf_test.json
            
            if timeout 180 npm run parse-research; then
              end_time=$(date +%s)
              duration=$((end_time - start_time))
              echo "âœ… Processing completed in ${duration} seconds"
              
              if [ $duration -gt 120 ]; then
                echo "âš ï¸ Processing time longer than expected"
              fi
            else
              echo "âš ï¸ Processing test timed out or failed"
            fi
          else
            echo "â„¹ï¸ Performance test skipped (no API key)"
          fi

  # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
  generate-report:
    name: ğŸ“‹ Generate QA Report
    runs-on: ubuntu-latest
    needs: [code-quality, security-audit, content-quality, performance-test]
    if: always()

    steps:
      - name: ğŸ“‹ Collect Results
        run: |
          echo "ğŸ“‹ Collecting quality assurance results..."
          
          code_status="${{ needs.code-quality.result }}"
          security_status="${{ needs.security-audit.result }}"
          content_status="${{ needs.content-quality.result }}"
          perf_status="${{ needs.performance-test.result }}"
          
          echo "### ğŸ” Quality Assurance Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Check Type | Status | Result |" >> $GITHUB_STEP_SUMMARY
          echo "|------------|--------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| ğŸ’» Code Quality | $([ "$code_status" = "success" ] && echo "âœ… Pass" || echo "âŒ Fail") | $code_status |" >> $GITHUB_STEP_SUMMARY
          echo "| ğŸ”’ Security Audit | $([ "$security_status" = "success" ] && echo "âœ… Pass" || echo "âŒ Fail") | $security_status |" >> $GITHUB_STEP_SUMMARY
          echo "| ğŸ“ Content Quality | $([ "$content_status" = "success" ] && echo "âœ… Pass" || echo "âŒ Fail") | $content_status |" >> $GITHUB_STEP_SUMMARY
          echo "| âš¡ Performance | $([ "$perf_status" = "success" ] && echo "âœ… Pass" || [ "$perf_status" = "skipped" ] && echo "â­ï¸ Skip" || echo "âŒ Fail") | $perf_status |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Overall Status**: $(
            if [ "$code_status" = "success" ] && [ "$security_status" = "success" ] && [ "$content_status" = "success" ] && ([ "$perf_status" = "success" ] || [ "$perf_status" = "skipped" ]); then
              echo "âœ… All checks passed"
            else
              echo "âš ï¸ Some checks failed"
            fi
          )" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Timestamp**: $(date -u)" >> $GITHUB_STEP_SUMMARY
          echo "**Workflow**: Quality Check #${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY

      - name: ğŸ“Š Upload QA Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: qa-report-${{ github.run_number }}
          path: |
            security-audit.json
            coverage/
          retention-days: 30
          if-no-files-found: ignore